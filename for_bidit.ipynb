{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, do `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will have our open AI key\n",
    "import json\n",
    "with open('secrets.json') as f:\n",
    "    secrets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = secrets[\"OPEN-AI-KEY\"]\n",
    "\n",
    "import wikienv, wrappers\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, stop=[\"\\n\"]):\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stop=stop\n",
    "    )\n",
    "\n",
    "    res = res['choices'][0]['message']['content']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = wikienv.WikiEnv()\n",
    "env = wrappers.FeverWrapper(env, split=\"train\")\n",
    "env = wrappers.LoggingWrapper(env)\n",
    "\n",
    "def step(env, action):\n",
    "    attempts = 0\n",
    "    while attempts < 10:\n",
    "        try:\n",
    "            return env.step(action)\n",
    "        except:\n",
    "            attempts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webthink_prompt = \"\"\"\n",
    "Reason about why the claim is supported, refuted, or has not enough information based on Wikipedia evidences.\n",
    "\n",
    "Claim: Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
    "Label: SUPPORTS\n",
    "Thought 1: I need to search Nikolaj Coster-Waldau and find if he has worked with the Fox Broadcasting Company.\n",
    "Action 1: Search[Nikolaj Coster-Waldau]\n",
    "Observation 1: Nikolaj William Coster-Waldau (born 27 July 1970) is a Danish actor and producer. He graduated from the Danish National School of Performing Arts in Copenhagen in 1993,[1] and had his breakthrough role in Denmark with the film Nightwatch (1994). He played Jaime Lannister in the HBO fantasy drama series Game of Thrones, for which he received two Primetime Emmy Award nominations for Outstanding Supporting Actor in a Drama Series.. Coster-Waldau has appeared in numerous films in his native Denmark and Scandinavia, including Headhunters (2011) and A Thousand Times Good Night (2013). In the U.S, his debut film role was in the war film Black Hawk Down (2001), playing Medal of Honor recipient Gary Gordon.[2] He then played a detective in the short-lived Fox television series New Amsterdam (2008), and appeared in the 2009 Fox television film Virtuality, originally intended as a pilot.\n",
    "Thought 2: Because he \"appeared in the 2009 Fox television film Virtuality\", he should have worked with the Fox Broadcasting Company. So, the claim is indeed supported by the evidence.\n",
    "Action 2: Finish[done]\n",
    "\n",
    "Claim: Stranger Things is set in Bloomington, Indiana.\n",
    "Label: REFUTES\n",
    "Thought 1: I should search for Stranger Things, and see if it is set in Bloomington, Indiana.\n",
    "Action 1: Search[Stranger Things]\n",
    "Observation 1: Stranger Things is an American science fiction horror drama television series created by the Duffer Brothers. Set in the 1980s, primarily in the fictional town of Hawkins, Indiana, the series centers on a number of mysteries and supernatural events occurring around the town and their impact on an ensemble of child and adult characters. \n",
    "Thought 2: The observation says that it is set in a \"fictional town of Hawkins, Indiana\", so it is not set in Bloomington. So, the claim is indeed refuted by the evidence.\n",
    "Action 2: Finish[done]\n",
    "\n",
    "Claim: Beautiful reached number two on the Billboard Hot 100 in 2003.?\n",
    "Label: NOT ENOUGH INFO\n",
    "Thought 1: I need to search the song Beautiful and find if it reached number two on the Billboard Hot 100 in 2003.\n",
    "Action 1: Search[Beautiful]\n",
    "Observation 1: Could not find [Beautiful]. Similar: ['Beautiful', 'Beautiful, Beautiful', 'A Beautiful Mind (film)', 'Beautiful (Christina Aguilera song)', 'Life Is Beautiful'].\n",
    "Thought 2: From suggestions, I should search \"Beautiful (Christina Aguilera song)\" to find the song.\n",
    "Action 2: Search[Beautiful (Christina Aguilera song)]\n",
    "Observation 2: \"Beautiful\" is a song recorded by American singer Christina Aguilera for her fourth studio album, Stripped (2002).\n",
    "Thought 3: It does not mention Billboard, so I need to look up \"Billboard Hot 100\" to find if it reached number two on it in 2003.\n",
    "Action 3: Lookup[Billboard Hot 100]\n",
    "Observation 3: (Result 1 / 3) The song peaked at number two on the Billboard Hot 100 in the United States, where it was certified Gold for 500,000 units shipped.\n",
    "Thought 4: It only says the song peaked at number two on the Billboard Hot 100, but not if it was in 2003. I am not sure if this claim is true or not. So, the evidence is indeed not sufficient to verify the claim.\n",
    "Action 4: Finish[done]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "d_train = load_dataset(\"fever\", \"v1.0\") # training set\n",
    "df_train = pd.DataFrame(d_train['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webthink(idx=None, prompt=webthink_prompt, to_print=False):\n",
    "    question = env.reset(idx=idx)\n",
    "    label = df_train[df_train['claim'] == question[7:]]['label'].values[0]\n",
    "\n",
    "    if to_print:\n",
    "        print(idx, question)\n",
    "    \n",
    "    prompt += question + \"\\n\"\n",
    "    prompt += \"Label: \" + label + \"\\n\"\n",
    "\n",
    "    n_calls, n_badcalls = 0, 0\n",
    "    for i in range(1, 8):\n",
    "        n_calls += 1\n",
    "        thought_action = llm(prompt + f\"Thought {i}:\", stop=[f\"\\nObservation {i}:\"])\n",
    "        try:\n",
    "            thought, action = thought_action.strip().split(f\"\\nAction {i}: \")\n",
    "        except:\n",
    "            #print('ohh...', thought_action)\n",
    "            n_badcalls += 1\n",
    "            n_calls += 1\n",
    "            thought = thought_action.strip().split('\\n')[0]\n",
    "            action = llm(prompt + f\"Thought {i}: {thought}\\nAction {i}:\", stop=[f\"\\n\"]).strip()\n",
    "        obs, r, done, info = step(env, action[0].lower() + action[1:])\n",
    "        obs = obs.replace('\\\\n', '')\n",
    "        step_str = f\"Thought {i}: {thought}\\nAction {i}: {action}\\nObservation {i}: {obs}\\n\"\n",
    "        prompt += step_str\n",
    "        if to_print:\n",
    "            print(step_str)\n",
    "        if done:\n",
    "            break\n",
    "    if not done:\n",
    "        obs, r, done, info = step(env, \"finish[]\")\n",
    "    if to_print:\n",
    "        print(info, '\\n')\n",
    "    info.update({'n_calls': n_calls, 'n_badcalls': n_badcalls, 'traj': prompt})\n",
    "    return r, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_react_reasoning_chains = pd.read_csv('data/react/df_react_chains_1381_forced_gt.csv')\n",
    "seen = df_react_reasoning_chains['question_idx'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 1500 examples, this loop may take about a day. It may also need manual intervention now and then (every few minutes) to make sure it doesnt get stuck. You can tell it is stuck if (when you clear the output) there is no new output for 20 seconds or so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = random.Random(233).shuffle(range(3000)) # use this seed\n",
    "num_to_process = 1500 # message Dean on slack how many you choose to process\n",
    "num_processed = 0\n",
    "infos = [] # holds our trajectories (and other info from react process)\n",
    "    \n",
    "for i in tqdm(idxs):\n",
    "    if i in seen:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        r, info = webthink(i, prompt=webthink_prompt)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    infos.append(info)\n",
    "\n",
    "    num_processed += 1\n",
    "    if num_processed == num_to_process:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save results to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for the new react prompt template (forcing it to give reasoning for ground truth)\n",
    "labels = []\n",
    "claims = []\n",
    "trajectories = []\n",
    "question_idxs = []\n",
    "n = 0\n",
    "for i in infos:\n",
    "    qi = i['question_idx']\n",
    "    a, ga = i['answer'], i['gt_answer']\n",
    "    traj = i['traj']\n",
    "\n",
    "    last_claim_chain = traj.split(\"Claim: \")[-1]\n",
    "    lines = last_claim_chain.split('\\n')\n",
    "    claim = lines[0]\n",
    "    trajectories.append(\"\\n\".join(lines[:-4]))\n",
    "\n",
    "    labels.append(ga)\n",
    "    claims.append(claim)\n",
    "    question_idxs.append(qi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_react_reasoning_chains = pd.DataFrame({\n",
    "    'question_idx': question_idxs,\n",
    "    'claim': claims,\n",
    "    'label': labels,\n",
    "    #'evidence': evidences,\n",
    "    #'assertions': assertions\n",
    "    'trajectories': trajectories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_react_reasoning_chains.to_csv('data/react/df_react_chains_next_1500_forced_gt.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
